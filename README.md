# Vision Transformer (ViT) Implementation in C++

## ğŸ‘¨â€ğŸ« Integrantes del Proyecto

- **Apaza Condori, Jhon Antony**  
- **Carazas Quispe, Alessander Jesus**  
- **MariÃ±os Hilario, Princce Yorwin**  
- **Mena Quispe, Sergio Sebastian Santos**

---

Este proyecto implementa desde cero un **Vision Transformer (ViT)** en **C++**, sin el uso de frameworks de aprendizaje profundo como PyTorch o TensorFlow. EstÃ¡ diseÃ±ado con fines educativos y demuestra cÃ³mo un modelo transformer puede adaptarse a tareas de visiÃ³n por computadora como la clasificaciÃ³n de imÃ¡genes, utilizando Ãºnicamente operaciones matriciales y lÃ³gica de bajo nivel.

El proyecto soporta entrenamiento y predicciÃ³n sobre los datasets **MNIST** (dÃ­gitos manuscritos) y **Fashion-MNIST** (ropa), y permite hacer inferencia con imÃ¡genes externas en formato `.jpg`.

---

## ğŸ§  Â¿QuÃ© es un Vision Transformer?

Los **Vision Transformers (ViT)** son una arquitectura que aplica el mecanismo de atenciÃ³n de los transformers (originalmente desarrollados para NLP) directamente sobre imÃ¡genes. En lugar de usar convoluciones, dividen la imagen en *patches*, los embeben como vectores y los procesan como una secuencia. Este proyecto implementa esa idea en C++ desde cero.

---

## ğŸ“ Estructura del Proyecto

.
â”œâ”€â”€ main.cpp                     # Entrenamiento en MNIST
â”œâ”€â”€ main_fashion.cpp            # Entrenamiento en Fashion-MNIST
â”œâ”€â”€ predict.cpp                 # PredicciÃ³n con modelo MNIST
â”œâ”€â”€ predict_fashion.cpp        # PredicciÃ³n con modelo Fashion-MNIST
â”œâ”€â”€ include/                    # Componentes del modelo ViT
â”‚   â”œâ”€â”€ vit_module.h
â”‚   â”œâ”€â”€ patch_embedding.h
â”‚   â”œâ”€â”€ encoder_block.h
â”‚   â”œâ”€â”€ multihead_attention.h
â”‚   â”œâ”€â”€ mlp.h
â”‚   â””â”€â”€ utils.h
â”œâ”€â”€ data/                       # Datasets e imÃ¡genes de prueba
â”‚   â”œâ”€â”€ mnist/
â”‚   â”œâ”€â”€ fashion-mnist/
â”‚   â”œâ”€â”€ pruebatest.jpg
â”‚   â””â”€â”€ pruebaropa.jpg
â”œâ”€â”€ entrenados/                 # Modelos entrenados y estadÃ­sticas
â”‚   â””â”€â”€ results/, results_fashion/
â”œâ”€â”€ CMakeLists.txt              # Archivo de compilaciÃ³n CMake

---

## âš™ï¸ Requisitos

- CMake 3.10 o superior
- Compilador con soporte C++17
- Eigen3 (para operaciones matriciales)
- OpenCV (para lectura de imÃ¡genes `.jpg`)

### En Ubuntu/Debian:

sudo apt update
sudo apt install cmake libeigen3-dev libopencv-dev g++

---

## ğŸ”§ CompilaciÃ³n

mkdir build
cd build
cmake ..
make

Esto generarÃ¡ ejecutables como `train_mnist`, `train_fashion`, `predict`, y `predict_fashion`.

---

## ğŸš€ Uso

### Entrenamiento en MNIST

./train_mnist

### Entrenamiento en Fashion-MNIST

./train_fashion

Al finalizar, el modelo entrenado y estadÃ­sticas se guardan automÃ¡ticamente en la carpeta `entrenados/`.

### PredicciÃ³n con imagen externa

1. tener una imagen en escala de grises de 28x28 px.
2. Ejecuta:

./predict data/pruebatest.jpg
./predict_fashion data/pruebaropa.jpg

VerÃ¡s una salida con la predicciÃ³n del modelo sobre la imagen.

---

## ğŸ“Š Resultados

Los entrenamientos generan estadÃ­sticas en archivos `.csv` (precisiÃ³n, pÃ©rdida por Ã©poca) dentro de `entrenados/results/`. Esto permite evaluar el rendimiento del modelo en validaciÃ³n y prueba.

---

## ğŸ“ MotivaciÃ³n

Este proyecto fue creado con fines didÃ¡cticos para entender los componentes internos de un Vision Transformer, implementando desde cero el flujo de:
- Embedding de patches
- AtenciÃ³n multi-cabeza
- NormalizaciÃ³n y capas MLP
- CÃ¡lculo de pÃ©rdida y entrenamiento

---